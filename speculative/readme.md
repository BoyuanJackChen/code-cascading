# Batched Speculative Inference of LLM

Don't expect accuracy with fp16.

## TODO: 
Edit generator.py to make it support multi-gpu
Implement early stopping